{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair Programming 30/05 Regresión lineal múltiple II - Tatiana y Guada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando paquetes! \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings( \"ignore\", module = \"seaborn\\..*\" )\n",
    "import sidetable\n",
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "Tomando los datos del mejor modelo obtenido en la clase de la pair de ayer.\n",
    "Investiga la multicolinealidad de las variables independientes.\n",
    "Selecciona aquellas variables que tengan una colinealidad dentro de los margenes estandar. Mostrando como se han ido eliminando las variables y como han cambiado los resultados del VIF.\n",
    "Realiza un modelo de regresión lineal multiple para ver si se han mejorado los resultados obtenidos.\n",
    "Estudia si tus resultados son acordes a las asunciones de linealidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('df_elegido.csv', index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numericas = df.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_VIF(dataframe, target):\n",
    "        X = add_constant(dataframe.loc[:, dataframe.columns != target])\n",
    "        seriesObject = pd.Series([variance_inflation_factor(X.values,i) for i in range(X.shape[1])] , index=X.columns,).sort_values(ascending= False)\n",
    "        return seriesObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tnr1234/anaconda3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1736: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/tnr1234/anaconda3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1736: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/tnr1234/anaconda3/lib/python3.9/site-packages/statsmodels/stats/outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "x0_ ?                        inf\n",
       "x0_ Federal-gov              inf\n",
       "x0_ Local-gov                inf\n",
       "x0_ Never-worked             inf\n",
       "x0_ Private                  inf\n",
       "x0_ Self-emp-inc             inf\n",
       "x0_ Self-emp-not-inc         inf\n",
       "x0_ State-gov                inf\n",
       "x0_ Without-pay              inf\n",
       "education-num           1.064752\n",
       "hours-per-week          1.047127\n",
       "age                     1.043744\n",
       "salary                  1.000283\n",
       "const                   0.000000\n",
       "capital-loss                 NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_VIF(df_numericas,'capital-gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable a eliminar por colinealidad es : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_VIF(df_numericas.drop(columns = ['xxxxxx']),'capital-gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo obtenido es : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2\n",
    "Toma ahora el dataset del mejor modelo obtenido y aplica los siguentes modelos de regresión con regularización.\n",
    "Ridge\n",
    "Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge\n",
    "\n",
    "x=df_diamantes_sin_outliers_encoded_oh_estandarizado.drop(columns = ['price'])\n",
    "y = df_diamantes_sin_outliers_encoded_oh_estandarizado['price']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Creamos la regresiónn lineal\n",
    "LR = Ridge(normalize= True) # nos aseguramos de que se normalizan los datos\n",
    "# Ajustamos el modelo\n",
    "\n",
    "LR.fit(x_train,y_train)\n",
    "y_prediction_train =  LR.predict(x_train)\n",
    "Adj_r2_train = 1 - (1-r2_score(y_train,y_prediction_train)) * (x_train.shape[0]-1)/(x_train.shape[0]-x_train.shape[1]-1)\n",
    "\n",
    "y_prediction =  LR.predict(x_test)\n",
    "Adj_r2_test = 1 - (1-r2_score(y_test, y_prediction)) * (x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)\n",
    "\n",
    "# Para el conjunto de entrenamiento las méticas han sido\n",
    "print('Para el conjunto train:---------------')\n",
    "print('El valor de r2 score es ',r2_score(y_train,y_prediction_train))\n",
    "print('El valor de r2 score adjusted es ',Adj_r2_train)\n",
    "print('El MAE es',mean_absolute_error(y_train,y_prediction_train))\n",
    "print('EL RMSE es ',np.sqrt(mean_squared_error(y_train,y_prediction_train)))\n",
    "\n",
    "\n",
    "# Para el conjunto de test las métricas han sido\n",
    "print('Para el conjunto test:---------------')\n",
    "print('El valor de r2 score es ',r2_score(y_test,y_prediction))\n",
    "print('El valor de r2 score adjusted es ',Adj_r2_test)\n",
    "print('El MAE es',mean_absolute_error(y_test,y_prediction))\n",
    "print('EL RMSE es ',np.sqrt(mean_squared_error(y_test,y_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso\n",
    "\n",
    "x=df_diamantes_sin_outliers_encoded_oh_estandarizado.drop(columns = ['price'])\n",
    "y = df_diamantes_sin_outliers_encoded_oh_estandarizado['price']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Creamos la regresiónn lineal\n",
    "LR = Lasso(normalize= True) # nos aseguramos de que se normalizan los datos\n",
    "# Ajustamos el modelo\n",
    "\n",
    "LR.fit(x_train,y_train)\n",
    "y_prediction_train =  LR.predict(x_train)\n",
    "Adj_r2_train = 1 - (1-r2_score(y_train,y_prediction_train)) * (x_train.shape[0]-1)/(x_train.shape[0]-x_train.shape[1]-1)\n",
    "\n",
    "y_prediction =  LR.predict(x_test)\n",
    "Adj_r2_test = 1 - (1-r2_score(y_test, y_prediction)) * (x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)\n",
    "\n",
    "# Para el conjunto de entrenamiento las méticas han sido\n",
    "print('Para el conjunto train:---------------')\n",
    "print('El valor de r2 score es ',r2_score(y_train,y_prediction_train))\n",
    "print('El valor de r2 score adjusted es ',Adj_r2_train)\n",
    "print('El MAE es',mean_absolute_error(y_train,y_prediction_train))\n",
    "print('EL RMSE es ',np.sqrt(mean_squared_error(y_train,y_prediction_train)))\n",
    "\n",
    "\n",
    "# Para el conjunto de test las métricas han sido\n",
    "print('Para el conjunto test:---------------')\n",
    "print('El valor de r2 score es ',r2_score(y_test,y_prediction))\n",
    "print('El valor de r2 score adjusted es ',Adj_r2_test)\n",
    "print('El MAE es',mean_absolute_error(y_test,y_prediction))\n",
    "print('EL RMSE es ',np.sqrt(mean_squared_error(y_test,y_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3\n",
    "Compara los resultados del ajuste lineal multiple donde se han eliminado variables y los obtenidos aplicando las regresiones de tipo Ridge y Lassso. Explica los resultados obtenidos."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "328661ec968ebc77b93161299d44fd1f4547ee33c9a17c5e95f23064c7c08def"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
